{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 16:52:29,853 - INFO - Chargement du graphe existant...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import logging\n",
    "import os\n",
    "import requests\n",
    "import dotenv\n",
    "from IPython.display import display, HTML, IFrame\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class KnowledgeGraph:\n",
    "    def __init__(self, similarity_threshold=0.8, base_url=None, api_key=None):\n",
    "        self.graph = nx.Graph()\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.df = None\n",
    "        self.base_url = base_url\n",
    "        self.headers = {\"Authorization\": f\"Bearer {api_key}\"} if api_key else {}\n",
    "\n",
    "    def load_data(self, file_path):\n",
    "        logging.info(\"Chargement des données...\")\n",
    "        self.df = pd.read_csv(file_path, sep='\\t')\n",
    "        self.df['content'] = self.df['content'].astype(str).replace('nan', '')\n",
    "        self.df['head'] = self.df['head'].astype(str).replace('nan', '')\n",
    "        self.df = self.df[self.df['content'].str.strip() != '']\n",
    "        logging.info(f\"Données chargées. Nombre d'articles : {len(self.df)}\")\n",
    "\n",
    "    def create_embeddings(self):\n",
    "        logging.info(\"Création des embeddings...\")\n",
    "        tqdm.pandas()  # Ceci active la barre de progression pour pandas\n",
    "        self.df['embedding'] = self.df['content'].progress_apply(lambda x: self.get_embedding(x))\n",
    "        logging.info(\"Embeddings créés.\")\n",
    "\n",
    "    def get_embedding(self, text):\n",
    "        url = f\"{self.base_url}/ollama/api/embeddings\"\n",
    "        payload = {\n",
    "            \"model\": \"mxbai-embed-large\",\n",
    "            \"prompt\": text\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=self.headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()['embedding']\n",
    "        else:\n",
    "            raise Exception(f\"Erreur lors de la génération de l'embedding: {response.text}\")\n",
    "\n",
    "    def build_graph(self):\n",
    "        logging.info(\"Construction du graphe...\")\n",
    "        for _, row in tqdm(self.df.iterrows(), total=len(self.df), desc=\"Ajout des nœuds\"):\n",
    "            node_id = str(row['id_enccre'])  # Conversion de l'ID en chaîne de caractères\n",
    "            self.graph.add_node(node_id, **row.to_dict())\n",
    "\n",
    "        embeddings = np.array(self.df['embedding'].tolist())\n",
    "        similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "        for i in tqdm(range(len(self.df)), desc=\"Ajout des arêtes\"):\n",
    "            for j in range(i+1, len(self.df)):\n",
    "                if similarity_matrix[i][j] > self.similarity_threshold:\n",
    "                    self.graph.add_edge(str(self.df.iloc[i]['id_enccre']), str(self.df.iloc[j]['id_enccre']), weight=similarity_matrix[i][j])\n",
    "\n",
    "        logging.info(f\"Graphe construit. Nombre de nœuds : {self.graph.number_of_nodes()}, Nombre d'arêtes : {self.graph.number_of_edges()}\")\n",
    "\n",
    "    def save_graph(self, file_path):\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "        logging.info(f\"Graphe sauvegardé dans {file_path}\")\n",
    "\n",
    "    @classmethod\n",
    "    def load_graph(cls, file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def get_node_info(self, node_id):\n",
    "        return self.graph.nodes[node_id]\n",
    "\n",
    "    def get_neighbors(self, node_id):\n",
    "        return list(self.graph.neighbors(node_id))\n",
    "\n",
    "    def get_subgraph(self, node_ids):\n",
    "        return self.graph.subgraph(node_ids)\n",
    "\n",
    "    def get_most_connected_nodes(self, n=10):\n",
    "        return sorted(self.graph.degree, key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "    def get_shortest_path(self, start_node, end_node):\n",
    "        return nx.shortest_path(self.graph, start_node, end_node)\n",
    "\n",
    "    def get_connected_components(self):\n",
    "        return list(nx.connected_components(self.graph))\n",
    "\n",
    "    \n",
    "    def visualize_graph(self, output_file='graph.html', height='500px', width='100%'):\n",
    "        \"\"\"\n",
    "        Visualise le graphe de connaissances interactivement.\n",
    "        \n",
    "        :param output_file: Nom du fichier HTML de sortie\n",
    "        :param height: Hauteur du graphe (en pixels ou pourcentage)\n",
    "        :param width: Largeur du graphe (en pixels ou pourcentage)\n",
    "        \"\"\"\n",
    "        nt = Network(height=height, width=width, notebook=True)\n",
    "        \n",
    "        # Ajout des nœuds\n",
    "        for node in self.graph.nodes():\n",
    "            node_id = str(node)  # Conversion de l'ID en chaîne de caractères\n",
    "            nt.add_node(node_id, label=self.graph.nodes[node].get('title', node_id))\n",
    "        \n",
    "        # Ajout des arêtes\n",
    "        for edge in self.graph.edges():\n",
    "            nt.add_edge(str(edge[0]), str(edge[1]))  # Conversion des IDs en chaînes de caractères\n",
    "        \n",
    "        # Sauvegarde et affichage\n",
    "        nt.save_graph(output_file)\n",
    "        return nt\n",
    "\n",
    "        \n",
    "    def visualize_subgraph(self, node_ids, output_file='subgraph.html', height=500, width=700):\n",
    "        subgraph = self.get_subgraph(node_ids)\n",
    "        nt = Network(notebook=True, cdn_resources='remote', height=f\"{height}px\", width=f\"{width}px\")\n",
    "        \n",
    "        for node in subgraph.nodes():\n",
    "            node_id = str(node)\n",
    "            node_data = subgraph.nodes[node]\n",
    "            label = node_data.get('head', node_id)  # Utiliser 'head' comme étiquette\n",
    "            title = f\"ID: {node_id}<br>Contenu: {node_data.get('content', '')[:100]}...\"  # Contenu affiché au survol\n",
    "            nt.add_node(node_id, label=label, title=title)\n",
    "        \n",
    "        for edge in subgraph.edges():\n",
    "            weight = subgraph[edge[0]][edge[1]].get('weight', 1)\n",
    "            nt.add_edge(str(edge[0]), str(edge[1]), value=weight)\n",
    "        \n",
    "        nt.set_options(\"\"\"\n",
    "        var options = {\n",
    "            \"nodes\": {\n",
    "                \"font\": {\n",
    "                    \"size\": 12\n",
    "                }\n",
    "            },\n",
    "            \"edges\": {\n",
    "                \"color\": {\n",
    "                    \"inherit\": true\n",
    "                },\n",
    "                \"smooth\": false\n",
    "            },\n",
    "            \"physics\": {\n",
    "                \"forceAtlas2Based\": {\n",
    "                    \"gravitationalConstant\": -26,\n",
    "                    \"centralGravity\": 0.005,\n",
    "                    \"springLength\": 230,\n",
    "                    \"springConstant\": 0.18\n",
    "                },\n",
    "                \"maxVelocity\": 146,\n",
    "                \"solver\": \"forceAtlas2Based\",\n",
    "                \"timestep\": 0.35,\n",
    "                \"stabilization\": {\n",
    "                    \"enabled\": true,\n",
    "                    \"iterations\": 1000,\n",
    "                    \"updateInterval\": 25\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \"\"\")\n",
    "        \n",
    "        # Sauvegarder le graphe\n",
    "        nt.save_graph(output_file)\n",
    "        \n",
    "        # Obtenir le chemin absolu du fichier\n",
    "        abs_file_path = os.path.abspath(output_file)\n",
    "        \n",
    "        # Afficher le graphe en utilisant IFrame\n",
    "        return IFrame(src=f'file://{abs_file_path}', width=width, height=height)\n",
    "\n",
    "class QueryEngine:\n",
    "    def __init__(self, knowledge_graph, base_url, api_key):\n",
    "        self.knowledge_graph = knowledge_graph\n",
    "        self.base_url = base_url\n",
    "        self.headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "\n",
    "    def get_embedding(self, text):\n",
    "        url = f\"{self.base_url}/ollama/api/embeddings\"\n",
    "        payload = {\n",
    "            \"model\": \"mxbai-embed-large\",\n",
    "            \"prompt\": text\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=self.headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()['embedding']\n",
    "        else:\n",
    "            raise Exception(f\"Erreur lors de la génération de l'embedding: {response.text}\")\n",
    "\n",
    "    def generate_response(self, prompt):\n",
    "        url = f\"{self.base_url}/ollama/api/generate\"\n",
    "        payload = {\n",
    "            \"model\": \"llama3.1:8b-instruct-q4_0\",\n",
    "            \"prompt\": f\"Voici une question d'un utiisateur : {prompt}. Réponds en t'aidant uniquement du contenu qui t'es fourni.\"\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=self.headers, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            full_response = \"\"\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    json_response = json.loads(line)\n",
    "                    full_response += json_response.get('response', '')\n",
    "                    if json_response.get('done', False):\n",
    "                        break\n",
    "            return full_response\n",
    "        else:\n",
    "            raise Exception(f\"Erreur lors de la génération de la réponse: {response.text}\")\n",
    "\n",
    "    def query(self, query: str):\n",
    "        logging.info(\"Traitement de la requête...\")\n",
    "        try:\n",
    "            embedding = self.get_embedding(query)\n",
    "            \n",
    "            # Trouver les nœuds les plus similaires\n",
    "            similarities = []\n",
    "            for node in self.knowledge_graph.graph.nodes():\n",
    "                node_embedding = self.knowledge_graph.graph.nodes[node]['embedding']\n",
    "                similarity = cosine_similarity([embedding], [node_embedding])[0][0]\n",
    "                similarities.append((node, similarity))\n",
    "            \n",
    "            # Trier par similarité décroissante et prendre les 5 premiers\n",
    "            most_similar = sorted(similarities, key=lambda x: x[1], reverse=True)[:5]\n",
    "            \n",
    "            context = \"\"\n",
    "            for node, _ in most_similar:\n",
    "                context += f\"\\n{self.knowledge_graph.graph.nodes[node]['content']}\"\n",
    "                # Ajouter le contenu des nœuds voisins\n",
    "                for neighbor in self.knowledge_graph.get_neighbors(node):\n",
    "                    context += f\"\\n{self.knowledge_graph.graph.nodes[neighbor]['content']}\"\n",
    "            \n",
    "            prompt = f\"Using this context: {context}\\nRespond to this query: {query}\"\n",
    "            response = self.generate_response(prompt)\n",
    "\n",
    "            return response, [node for node, _ in most_similar], [self.knowledge_graph.graph.nodes[node]['content'] for node, _ in most_similar]\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erreur lors du traitement de la requête : {str(e)}\")\n",
    "            logging.error(f\"Type d'erreur : {type(e).__name__}\")\n",
    "            logging.error(f\"Détails de l'erreur : {e.args}\")\n",
    "            return \"Désolé, je n'ai pas pu traiter votre requête.\", [], []\n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self, data_file, base_url, api_key):\n",
    "        self.data_file = data_file\n",
    "        self.base_url = base_url\n",
    "        self.api_key = api_key\n",
    "        self.knowledge_graph = None\n",
    "        self.query_engine = None\n",
    "\n",
    "    def initialize(self):\n",
    "        graph_file = \"knowledge_graph.pkl\"\n",
    "        if os.path.exists(graph_file):\n",
    "            logging.info(\"Chargement du graphe existant...\")\n",
    "            self.knowledge_graph = KnowledgeGraph.load_graph(graph_file)\n",
    "        else:\n",
    "            logging.info(\"Création d'un nouveau graphe...\")\n",
    "            self.knowledge_graph = KnowledgeGraph(base_url=self.base_url, api_key=self.api_key)\n",
    "            self.knowledge_graph.load_data(self.data_file)\n",
    "            self.knowledge_graph.create_embeddings()\n",
    "            self.knowledge_graph.build_graph()\n",
    "            self.knowledge_graph.save_graph(graph_file)\n",
    "\n",
    "        self.query_engine = QueryEngine(self.knowledge_graph, self.base_url, self.api_key)\n",
    "\n",
    "    def chat(self, user_query):\n",
    "        try:\n",
    "            response, doc_ids, doc_contents = self.query_engine.query(user_query)\n",
    "            \n",
    "            print(f\"Réponse : {response}\\n\")\n",
    "            print(\"Sources pertinentes :\")\n",
    "            for i, (doc_id, content) in enumerate(zip(doc_ids, doc_contents), 1):\n",
    "                print(f\"{i}. ID: {doc_id}\")\n",
    "                print(f\"   Contenu: {content[:100]}...\\n\")\n",
    "            \n",
    "            # Visualisation du sous-graphe\n",
    "            print(\"Visualisation du sous-graphe :\")\n",
    "            subgraph_viz = self.knowledge_graph.visualize_subgraph(doc_ids, output_file='query_subgraph.html')\n",
    "            display(subgraph_viz)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du traitement de la requête : {str(e)}\")\n",
    "\n",
    "# Initialisation du chatbot\n",
    "BASE_URL = \"https://lemum.duckdns.org\"\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "chatbot = Chatbot(\"data/EDdA_dataframe_withContent_test.tsv\", BASE_URL, API_KEY)\n",
    "chatbot.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 16:52:39,357 - INFO - Traitement de la requête...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse : Voici quelques exemples récents d'abdication que j'ai trouvés dans le texte :\n",
      "\n",
      "* Dioclétien a abdiqué la Couronne.\n",
      "* Charles V. a abdiqué la Couronne.\n",
      "* Le Parlement d'Angleterre a décidé que la violation des Lois faite par le Roi Jacques, en quittant son Royaume sans avoir pourvû à l'administration nécessaire des affaires pendant son absence, emportoit avec elle l'abdication de la Couronne.\n",
      "\n",
      "Notez également que l'exemple du roi Philippe IV d'Espagne qui a \"résigné\" la Couronne est mentionné dans le texte, mais cela constitue une différence avec l'abdication, car il s'est fait en faveur d'une personne tierce.\n",
      "\n",
      "Sources pertinentes :\n",
      "1. ID: v1-95-3\n",
      "   Contenu: Abdication, au Palais, est aussi quelquefois synonyme \n",
      "à abandonnement. V. Abandonnement.\n",
      "(H)...\n",
      "\n",
      "2. ID: v1-95-2\n",
      "   Contenu: Abdication s'est dit encore de l'action d'un homme \n",
      "libre qui renonçoit à sa liberté, & se faisoit v...\n",
      "\n",
      "3. ID: v1-95-0\n",
      "   Contenu: ABDICATION, s. f. acte par lequel un Magistrat\n",
      "ou une personne en Charge y renonce, & s'en démet\n",
      "ava...\n",
      "\n",
      "4. ID: v1-95-1\n",
      "   Contenu: Abdication dans le Droit civil, se prend particulierement \n",
      "pour l'acte par lequel un pere congédie\n",
      "&...\n",
      "\n",
      "5. ID: v1-82-3\n",
      "   Contenu: Abbé, est aussi un titre qu'ont porté différens Magistrats, ou autres personnes laïques. Parmi les G...\n",
      "\n",
      "Visualisation du sous-graphe :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"500\"\n",
       "            src=\"file://c:\\Users\\moblange\\OneDrive\\Bureau\\Programmation\\EncyclopedIA\\query_subgraph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1fa43a93b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "chatbot.chat(\"Donne moi des exemples récents d'abdication.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
